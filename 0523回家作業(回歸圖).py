import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('TkAgg')  # ä¿®æ­£ PyCharm é¡¯ç¤ºéŒ¯èª¤
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from scipy.stats import zscore

# è¨­å®šå­—å‹é¿å…ä¸­æ–‡äº‚ç¢¼ï¼ˆWindows ä½¿ç”¨è€…ï¼‰
plt.rcParams['font.family'] = 'Microsoft JhengHei'

# è®€å–è³‡æ–™
df = pd.read_csv("eccentricity.csv")

# ç¼ºå€¼è™•ç†
print("ğŸ” ç¼ºå€¼æª¢æŸ¥çµæœï¼š")
print(df.isnull().sum())
df = df.dropna()

# Boxplot æª¢æŸ¥ç•°å¸¸å€¼
plt.figure(figsize=(10, 5))
sns.boxplot(data=df[['speedSet', 'load_value', 'sensor1']])
plt.title("æ•¸æ“šç•°å¸¸å€¼æª¢æŸ¥ï¼ˆBoxplotï¼‰")
plt.tight_layout()
plt.savefig("boxplot_outliers.png")
plt.show()

# Z-score æª¢æŸ¥ç•°å¸¸å€¼
z_scores = np.abs(zscore(df[['speedSet', 'load_value', 'sensor1']]))
outlier_counts = (z_scores > 3).sum(axis=0)
print("\nZ-score > 3 çš„ç•°å¸¸å€¼å€‹æ•¸ï¼š")
print(outlier_counts)

# é¡¯ç¤ºæ¬„ä½è³‡è¨Š
print(f"\næ¨£æœ¬æ•¸ï¼š{df.shape[0]}, ç‰¹å¾µæ•¸ï¼ˆå«ç›®æ¨™ï¼‰ï¼š{df.shape[1]}")
print("æ¬„ä½åç¨±ï¼š", df.columns.tolist())

# ç‰¹å¾µèˆ‡ç›®æ¨™è¨­å®š
features = ['speedSet', 'load_value']
target = 'sensor1'

X = df[features]
y = df[target]

# ç‰¹å¾µæ¨™æº–åŒ–
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# è³‡æ–™åˆ‡åˆ†
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# å¤šé …å¼è½‰æ›
poly = PolynomialFeatures(degree=2, include_bias=False)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

# æ¨¡å‹å®šç¾©
models = {
    "Linear Regression": LinearRegression(),
    "Polynomial Regression (deg=2)": LinearRegression(),
    "Ridge Regression": Ridge(alpha=1.0),
    "Lasso Regression": Lasso(alpha=0.1),
    "ElasticNet Regression": ElasticNet(alpha=0.1, l1_ratio=0.5)
}

# RMSE å‡½æ•¸
def rmse(y_true, y_pred):
    return mean_squared_error(y_true, y_pred, squared=False)

results = {}
y_preds = {}

# æ¨¡å‹è¨“ç·´èˆ‡è©•ä¼°
for name, model in models.items():
    if "Polynomial" in name:
        model.fit(X_train_poly, y_train)
        y_pred = model.predict(X_test_poly)
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

    r2 = r2_score(y_test, y_pred)
    rmse_val = rmse(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100

    results[name] = {"RÂ²": r2, "RMSE": rmse_val, "MAE": mae, "MAPE": mape}
    y_preds[name] = y_pred

# çµæœ DataFrame
result_df = pd.DataFrame(results).T.sort_values("RÂ²", ascending=False)
print("\nğŸ“Š æ¨¡å‹è©•ä¼°æŒ‡æ¨™ï¼š")
print(result_df)

# æœ€ä½³æ¨¡å‹
best_model_name = result_df.index[0]
best_y_pred = y_preds[best_model_name]

# çœŸå¯¦ vs é æ¸¬åœ–
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=best_y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("å¯¦éš›å€¼")
plt.ylabel("é æ¸¬å€¼")
plt.title(f"{best_model_name} - å¯¦éš› vs é æ¸¬")
plt.tight_layout()
plt.savefig("true_vs_pred.png")
plt.show()

# æ®˜å·®åœ–
errors = y_test - best_y_pred
plt.figure(figsize=(8, 6))
sns.histplot(errors, kde=True, bins=30)
plt.title(f"{best_model_name} - æ®˜å·®åˆ†å¸ƒ")
plt.xlabel("æ®˜å·®ï¼ˆé æ¸¬èª¤å·®ï¼‰")
plt.tight_layout()
plt.savefig("residuals.png")
plt.show()

# RÂ² æ¨¡å‹æ¯”è¼ƒ
plt.figure(figsize=(10, 6))
colors = plt.cm.viridis(np.linspace(0, 1, len(result_df)))
plt.bar(result_df.index, result_df["RÂ²"], color=colors)
plt.title("å„æ¨¡å‹ RÂ² æ¯”è¼ƒ")
plt.ylabel("RÂ²")
plt.xticks(rotation=30)
plt.tight_layout()
plt.savefig("r2_comparison.png")
plt.show()

# çµè«–è¼¸å‡º
print(f"\nâœ… çµè«–ï¼š")
print(f"æœ€ä½³æ¨¡å‹ç‚ºï¼š{best_model_name}")
print(f"å…¶ RÂ² = {result_df.loc[best_model_name, 'RÂ²']:.4f}ï¼ŒRMSE = {result_df.loc[best_model_name, 'RMSE']:.4f}")
print("è©²æ¨¡å‹å¯èƒ½æ•ˆæœè¼ƒå¥½ï¼Œå› ç‚ºè³‡æ–™å…·å‚™ {}ã€‚".format(
    'éç·šæ€§ç‰¹å¾µ' if 'Polynomial' in best_model_name else 'ç·šæ€§æˆ–æ­£å‰‡åŒ–éœ€æ±‚'
))
